{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from baseline import load_model\n",
    "from config import test_parser\n",
    "from time import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'E:\\\\gradContext\\\\课程\\\\研一下\\\\智能信息\\\\twvrp\\\\GCN-NPEC\\\\src\\\\custumer.csv'\n",
    "# 引入目标点custumer\n",
    "points = pd.read_csv(filename, header=None)\n",
    "# print(points)\n",
    "X = points.iloc[:, 0].values.T\n",
    "Y = points.iloc[:, 1].values.T\n",
    "Q = points.iloc[:, 2].values.T\n",
    "num = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 21, 2)\n"
     ]
    }
   ],
   "source": [
    "file_path=\"E:\\\\gradContext\\\\课程\\\\研一下\\\\智能信息\\\\twvrp\\\\GCN-NPEC\\\\src\\\\my-20-testing.npz\"\n",
    "poem=np.load(file_path,allow_pickle=True)\n",
    "print(poem['graph'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coor_min = min(min(X), min(Y))\n",
    "coor_max = max(max(X), max(Y))\n",
    "x = (X-coor_min)/(coor_max-coor_min)\n",
    "y = (Y-coor_min)/(coor_max-coor_min)\n",
    "q = ((Q-min(Q))/(400-min(Q)))[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = np.zeros([1,num, num])\n",
    "for i in range(num):\n",
    "    for j in range(num):\n",
    "        dis[0][i][j] = np.sqrt((x[i]-x[j])**2+(y[i]-y[j])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('my-0-training.npz', graph = np.dstack((x,y)), demand = q, dis = dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ge_test_data(device, size, n_customer):\n",
    "    graph = np.dstack((x,y))\n",
    "    depot_xy = graph[0:size, 0, :]\n",
    "    customer_xy = graph[0:size, 1:n_customer, :]\n",
    "    demand = q[0:size:, 1:n_customer]\n",
    "    dist = dis[0:size]\n",
    "\n",
    "    return (torch.tensor(np.expand_dims(np.array(depot_xy), axis = 0), dtype = torch.float).squeeze(0), \n",
    "\t\t\ttorch.tensor(np.expand_dims(np.array(customer_xy), axis = 0), dtype = torch.float).squeeze(0), \n",
    "\t\t\ttorch.tensor(np.expand_dims(np.array(demand), axis = 0), dtype = torch.float).squeeze(0),\n",
    "            torch.tensor(np.expand_dims(np.array(dist), axis = 0), dtype = torch.float).squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parser1():\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\t#parser.add_argument('-p', '--path', metavar = 'P', type = str, required = True, help = 'Weights/VRP***_train_epoch***.pt, pt file required')\n",
    "\tparser.add_argument('-b', '--batch', metavar = 'B', type = int, default = 2, help = 'batch size')\n",
    "\tparser.add_argument('-n', '--n_customer', metavar = 'N', type = int, default = 40, help = 'number of customer nodes, time sequence')\n",
    "\tparser.add_argument('-s', '--seed', metavar = 'S', type = int, default = 123, help = 'random seed number for inference, reproducibility')\n",
    "\tparser.add_argument('-t', '--txt', metavar = 'T', type = str, help = 'if you wanna test out on text file, example: ../OpenData/A-n53-k7.txt')\n",
    "\tparser.add_argument('-d', '--decode_type', metavar = 'D', default = 'sampling', type = str, choices = ['greedy', 'sampling'], help = 'greedy or sampling, default sampling')\n",
    "\t\n",
    "\t#args = parser.parse_args()\n",
    "\targs = parser.parse_known_args()[0]\n",
    "\treturn args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading time:0.012856006622314453s\n",
      "torch.Size([1, 41, 2])\n",
      "data generate time:0.0s\n"
     ]
    }
   ],
   "source": [
    "args = test_parser1()\n",
    "path = \"E:\\\\gradContext\\\\课程\\研一下\\\\智能信息\\\\twvrp\\\\GCN-NPEC\\\\src\\\\Weights\\\\VRP40_train_epoch9.pt\"\n",
    "t1 = time()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained = load_model(path, embed_dim = 64, n_customer = 42, n_encode_layers = 3)\n",
    "print(f'model loading time:{time()-t1}s')\n",
    "t2 = time()\n",
    "data = ge_test_data(device, 1, n_customer=42)\n",
    "print(data[1].shape)\n",
    "print(f'data generate time:{time()-t2}s')\n",
    "# \tprint(data[1].shape, data[2].shape, data[3].shape)\n",
    "pretrained = pretrained.to(device)\n",
    "pretrained.eval()\n",
    "with torch.no_grad():\n",
    "    costs, _, pi, _, _ = pretrained(data, return_pi = True, decode_type = args.decode_type)\n",
    "# print('costs:', costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "route = pi[torch.argmin(costs, dim = 0)].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "route\n",
    "pos = np.where(route > 0)[0]\n",
    "split = np.where(np.diff(pos) != 1)[0] + 1\n",
    "arr = np.split(route[pos], split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 5, 8, 7, 6, 15, 14, 3, 2, 0], [0, 23, 1, 22, 31, 10, 9, 20, 0], [0, 4, 13, 21, 16, 19, 17, 24, 12, 0], [0, 11, 32, 29, 18, 40, 25, 28, 0], [0, 33, 27, 30, 37, 38, 34, 26, 36, 0], [0, 35, 41, 39, 0]]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for p in arr:\n",
    "    p = np.pad(p,(1,1),'constant', constant_values=0) \n",
    "    res.append(p.tolist())\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_raw = np.zeros([num, num])\n",
    "for i in range(num):\n",
    "    for j in range(num):\n",
    "        dis_raw[i][j] = np.sqrt((X[i]-X[j])**2+(Y[i]-Y[j])**2)\n",
    "dis_raw  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_vec_dis = []\n",
    "for route in res:\n",
    "    dis = 0\n",
    "    for id in range(len(route)-1):\n",
    "        dis+=dis_raw[route[id]][route[id+1]]\n",
    "    each_vec_dis.append(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3184.679581991972,\n",
       " 5978.310599611918,\n",
       " 3869.0009566645226,\n",
       " 7444.082902186643,\n",
       " 7519.554004768485,\n",
       " 4536.899598627994]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_vec_dis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
